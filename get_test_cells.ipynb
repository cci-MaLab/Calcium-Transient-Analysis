{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to indentify what cells were used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open test_results.pkl\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "from core.backend import open_minian\n",
    "\n",
    "with open('test_results.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through experiments\n",
    "dict = {\"cross_session_same_day\": [[\"./data/PL010/PL010_D1S1\", \"./data/PL010/PL010_D1S4\"], [\"./data/AA058/AA058_D1S1\", \"./data/AA058/AA058_D1S4\"], [\"./data/AA036/AA036_D2S1\", \"./data/AA036/AA036_D2S4\"], [\"./data/AA034/AA034_D1S1\", \"./data/AA034/AA034_D1S4\"]],\n",
    "        \"cross_day_same_session\": [[\"./data/PL010/PL010_D1S1\", \"./data/PL010/PL010_D8S1\"], [\"./data/AA058/AA058_D1S1\", \"./data/AA058/AA058_D5S1\"], [\"./data/AA036/AA036_D2S1\", \"./data/AA036/AA036_D6S1\"], [\"./data/AA034/AA034_D1S1\", \"./data/AA034/AA034_D7S1\"]],\n",
    "        \"cross_day_cross_session\": [[\"./data/PL010/PL010_D1S1\", \"./data/PL010/PL010_D8S4\"], [\"./data/AA058/AA058_D1S1\", \"./data/AA058/AA058_D5S4\"], [\"./data/AA036/AA036_D2S1\", \"./data/AA036/AA036_D6S4\"], [\"./data/AA034/AA034_D1S1\", \"./data/AA034/AA034_D7S4\"]],\n",
    "        \"cross_animal\": [[\"./data/PL010/PL010_D1S1\", \"./data/AA058/AA058_D1S1\"], [\"./data/AA058/AA058_D1S1\", \"./data/AA036/AA036_D2S1\"], [\"./data/AA036/AA036_D2S1\", \"./data/AA034/AA034_D1S1\"], [\"./data/AA034/AA034_D1S1\", \"./data/PL010/PL010_D1S1\"]],\n",
    "        \"within_session\": [[\"./data/PL010/PL010_D1S1\"], [\"./data/AA058/AA058_D1S1\"], [\"./data/AA036/AA036_D2S1\"], [\"./data/AA034/AA034_D1S1\"]]}\n",
    "\n",
    "experiments = results.keys()\n",
    "\n",
    "def find_test_set(experiment, training_set):\n",
    "        arr = dict[experiment]\n",
    "        if len(arr[0]) == 1:\n",
    "                for train in arr:\n",
    "                        if train[0][-len(training_set):] == training_set:\n",
    "                                return train[0]\n",
    "        else:\n",
    "                for train, test in arr:\n",
    "                        if train[-len(training_set):] == training_set:\n",
    "                                return test\n",
    "        print(f\"Error: Test set not found for {experiment} and {training_set}\")\n",
    "\n",
    "def get_ground_truth(arr):\n",
    "        # Get rows 0, 2, 4 etc. from the array\n",
    "        return arr[::2]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 1, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 1]], dtype=int8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"cross_session_same_day\"][\"AA034_D1S1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\milange\\Cell_Clustering_Tool\\core\\backend.py:87: RuntimeWarning: Failed to open Zarr store with consolidated metadata, but successfully read with non-consolidated metadata. This is typically much slower for opening a dataset. To silence this warning, consider:\n",
      "1. Consolidating metadata in this existing store with zarr.consolidate_metadata().\n",
      "2. Explicitly setting consolidated=False, to avoid trying to read consolidate metadata, or\n",
      "3. Explicitly setting consolidated=True, to raise an error in this case instead of falling back to try reading non-consolidated metadata.\n",
      "  arr = list(xr.open_zarr(arr_path).values())[0]\n",
      "e:\\milange\\Cell_Clustering_Tool\\core\\backend.py:87: RuntimeWarning: Failed to open Zarr store with consolidated metadata, but successfully read with non-consolidated metadata. This is typically much slower for opening a dataset. To silence this warning, consider:\n",
      "1. Consolidating metadata in this existing store with zarr.consolidate_metadata().\n",
      "2. Explicitly setting consolidated=False, to avoid trying to read consolidate metadata, or\n",
      "3. Explicitly setting consolidated=True, to raise an error in this case instead of falling back to try reading non-consolidated metadata.\n",
      "  arr = list(xr.open_zarr(arr_path).values())[0]\n",
      "e:\\milange\\Cell_Clustering_Tool\\core\\backend.py:87: RuntimeWarning: Failed to open Zarr store with consolidated metadata, but successfully read with non-consolidated metadata. This is typically much slower for opening a dataset. To silence this warning, consider:\n",
      "1. Consolidating metadata in this existing store with zarr.consolidate_metadata().\n",
      "2. Explicitly setting consolidated=False, to avoid trying to read consolidate metadata, or\n",
      "3. Explicitly setting consolidated=True, to raise an error in this case instead of falling back to try reading non-consolidated metadata.\n",
      "  arr = list(xr.open_zarr(arr_path).values())[0]\n",
      "C:\\Users\\milange\\AppData\\Local\\Temp\\2\\ipykernel_10096\\954953806.py:15: RuntimeWarning: invalid value encountered in cast\n",
      "  verified = E.verified.values.astype(int)\n",
      "e:\\milange\\Cell_Clustering_Tool\\core\\backend.py:87: RuntimeWarning: Failed to open Zarr store with consolidated metadata, but successfully read with non-consolidated metadata. This is typically much slower for opening a dataset. To silence this warning, consider:\n",
      "1. Consolidating metadata in this existing store with zarr.consolidate_metadata().\n",
      "2. Explicitly setting consolidated=False, to avoid trying to read consolidate metadata, or\n",
      "3. Explicitly setting consolidated=True, to raise an error in this case instead of falling back to try reading non-consolidated metadata.\n",
      "  arr = list(xr.open_zarr(arr_path).values())[0]\n",
      "e:\\milange\\Cell_Clustering_Tool\\core\\backend.py:87: RuntimeWarning: Failed to open Zarr store with consolidated metadata, but successfully read with non-consolidated metadata. This is typically much slower for opening a dataset. To silence this warning, consider:\n",
      "1. Consolidating metadata in this existing store with zarr.consolidate_metadata().\n",
      "2. Explicitly setting consolidated=False, to avoid trying to read consolidate metadata, or\n",
      "3. Explicitly setting consolidated=True, to raise an error in this case instead of falling back to try reading non-consolidated metadata.\n",
      "  arr = list(xr.open_zarr(arr_path).values())[0]\n",
      "e:\\milange\\Cell_Clustering_Tool\\core\\backend.py:87: RuntimeWarning: Failed to open Zarr store with consolidated metadata, but successfully read with non-consolidated metadata. This is typically much slower for opening a dataset. To silence this warning, consider:\n",
      "1. Consolidating metadata in this existing store with zarr.consolidate_metadata().\n",
      "2. Explicitly setting consolidated=False, to avoid trying to read consolidate metadata, or\n",
      "3. Explicitly setting consolidated=True, to raise an error in this case instead of falling back to try reading non-consolidated metadata.\n",
      "  arr = list(xr.open_zarr(arr_path).values())[0]\n",
      "e:\\milange\\Cell_Clustering_Tool\\core\\backend.py:87: RuntimeWarning: Failed to open Zarr store with consolidated metadata, but successfully read with non-consolidated metadata. This is typically much slower for opening a dataset. To silence this warning, consider:\n",
      "1. Consolidating metadata in this existing store with zarr.consolidate_metadata().\n",
      "2. Explicitly setting consolidated=False, to avoid trying to read consolidate metadata, or\n",
      "3. Explicitly setting consolidated=True, to raise an error in this case instead of falling back to try reading non-consolidated metadata.\n",
      "  arr = list(xr.open_zarr(arr_path).values())[0]\n",
      "C:\\Users\\milange\\AppData\\Local\\Temp\\2\\ipykernel_10096\\954953806.py:15: RuntimeWarning: invalid value encountered in cast\n",
      "  verified = E.verified.values.astype(int)\n",
      "e:\\milange\\Cell_Clustering_Tool\\core\\backend.py:87: RuntimeWarning: Failed to open Zarr store with consolidated metadata, but successfully read with non-consolidated metadata. This is typically much slower for opening a dataset. To silence this warning, consider:\n",
      "1. Consolidating metadata in this existing store with zarr.consolidate_metadata().\n",
      "2. Explicitly setting consolidated=False, to avoid trying to read consolidate metadata, or\n",
      "3. Explicitly setting consolidated=True, to raise an error in this case instead of falling back to try reading non-consolidated metadata.\n",
      "  arr = list(xr.open_zarr(arr_path).values())[0]\n",
      "C:\\Users\\milange\\AppData\\Local\\Temp\\2\\ipykernel_10096\\954953806.py:15: RuntimeWarning: invalid value encountered in cast\n",
      "  verified = E.verified.values.astype(int)\n",
      "e:\\milange\\Cell_Clustering_Tool\\core\\backend.py:87: RuntimeWarning: Failed to open Zarr store with consolidated metadata, but successfully read with non-consolidated metadata. This is typically much slower for opening a dataset. To silence this warning, consider:\n",
      "1. Consolidating metadata in this existing store with zarr.consolidate_metadata().\n",
      "2. Explicitly setting consolidated=False, to avoid trying to read consolidate metadata, or\n",
      "3. Explicitly setting consolidated=True, to raise an error in this case instead of falling back to try reading non-consolidated metadata.\n",
      "  arr = list(xr.open_zarr(arr_path).values())[0]\n",
      "e:\\milange\\Cell_Clustering_Tool\\core\\backend.py:87: RuntimeWarning: Failed to open Zarr store with consolidated metadata, but successfully read with non-consolidated metadata. This is typically much slower for opening a dataset. To silence this warning, consider:\n",
      "1. Consolidating metadata in this existing store with zarr.consolidate_metadata().\n",
      "2. Explicitly setting consolidated=False, to avoid trying to read consolidate metadata, or\n",
      "3. Explicitly setting consolidated=True, to raise an error in this case instead of falling back to try reading non-consolidated metadata.\n",
      "  arr = list(xr.open_zarr(arr_path).values())[0]\n",
      "C:\\Users\\milange\\AppData\\Local\\Temp\\2\\ipykernel_10096\\954953806.py:15: RuntimeWarning: invalid value encountered in cast\n",
      "  verified = E.verified.values.astype(int)\n",
      "e:\\milange\\Cell_Clustering_Tool\\core\\backend.py:87: RuntimeWarning: Failed to open Zarr store with consolidated metadata, but successfully read with non-consolidated metadata. This is typically much slower for opening a dataset. To silence this warning, consider:\n",
      "1. Consolidating metadata in this existing store with zarr.consolidate_metadata().\n",
      "2. Explicitly setting consolidated=False, to avoid trying to read consolidate metadata, or\n",
      "3. Explicitly setting consolidated=True, to raise an error in this case instead of falling back to try reading non-consolidated metadata.\n",
      "  arr = list(xr.open_zarr(arr_path).values())[0]\n",
      "e:\\milange\\Cell_Clustering_Tool\\core\\backend.py:87: RuntimeWarning: Failed to open Zarr store with consolidated metadata, but successfully read with non-consolidated metadata. This is typically much slower for opening a dataset. To silence this warning, consider:\n",
      "1. Consolidating metadata in this existing store with zarr.consolidate_metadata().\n",
      "2. Explicitly setting consolidated=False, to avoid trying to read consolidate metadata, or\n",
      "3. Explicitly setting consolidated=True, to raise an error in this case instead of falling back to try reading non-consolidated metadata.\n",
      "  arr = list(xr.open_zarr(arr_path).values())[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AA034_D1S1 within_session\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\milange\\Cell_Clustering_Tool\\core\\backend.py:87: RuntimeWarning: Failed to open Zarr store with consolidated metadata, but successfully read with non-consolidated metadata. This is typically much slower for opening a dataset. To silence this warning, consider:\n",
      "1. Consolidating metadata in this existing store with zarr.consolidate_metadata().\n",
      "2. Explicitly setting consolidated=False, to avoid trying to read consolidate metadata, or\n",
      "3. Explicitly setting consolidated=True, to raise an error in this case instead of falling back to try reading non-consolidated metadata.\n",
      "  arr = list(xr.open_zarr(arr_path).values())[0]\n",
      "C:\\Users\\milange\\AppData\\Local\\Temp\\2\\ipykernel_10096\\954953806.py:15: RuntimeWarning: invalid value encountered in cast\n",
      "  verified = E.verified.values.astype(int)\n",
      "e:\\milange\\Cell_Clustering_Tool\\core\\backend.py:87: RuntimeWarning: Failed to open Zarr store with consolidated metadata, but successfully read with non-consolidated metadata. This is typically much slower for opening a dataset. To silence this warning, consider:\n",
      "1. Consolidating metadata in this existing store with zarr.consolidate_metadata().\n",
      "2. Explicitly setting consolidated=False, to avoid trying to read consolidate metadata, or\n",
      "3. Explicitly setting consolidated=True, to raise an error in this case instead of falling back to try reading non-consolidated metadata.\n",
      "  arr = list(xr.open_zarr(arr_path).values())[0]\n"
     ]
    }
   ],
   "source": [
    "test_cells_dict = {}\n",
    "\n",
    "for experiment in experiments:\n",
    "    test_cells_dict[experiment] = {}\n",
    "    training_sets = results[experiment].keys()\n",
    "    for training_set in training_sets:\n",
    "        test_cells_dict[experiment][training_set] = {}\n",
    "        if experiment == \"within_session\" and training_set == \"AA034_D1S1\":\n",
    "            print(training_set + \" \" + experiment)\n",
    "        test_set = find_test_set(experiment, training_set)\n",
    "        E = open_minian(test_set)[\"E\"].load()\n",
    "        test_set = test_set.split(\"/\")[-1]\n",
    "        test_cells_dict[experiment][training_set][test_set] = []\n",
    "        all_unit_ids = E.unit_id.values\n",
    "        verified = E.verified.values.astype(int)\n",
    "        unit_ids = all_unit_ids[verified==1]\n",
    "        E = E.sel(unit_id=unit_ids)\n",
    "        ground_truth = get_ground_truth(results[experiment][training_set])\n",
    "        # We need to match the ground truth with the results in E and return the name of the cell\n",
    "        for row in ground_truth:\n",
    "            # This took me a while to figure out but I made a small mistake when trying to generate the data, I used 26999 frames instead of 27000\n",
    "            # Split the row into 5 equal parts\n",
    "            mini_rows = np.array_split(row, 5)\n",
    "            mini_indices = []\n",
    "            for mini_r in mini_rows:\n",
    "                found = False\n",
    "                for unit_id in unit_ids:\n",
    "                    if (E.sel(unit_id=unit_id).values[:-1] == mini_r).all():\n",
    "                        mini_indices.append(unit_id)\n",
    "                        found = True\n",
    "                        break\n",
    "            \n",
    "                if not found:\n",
    "                    raise Exception(f\"Error: Cell not found in test set {test_set} for experiment {experiment} and training set {training_set}\")\n",
    "                \n",
    "            test_cells_dict[experiment][training_set][test_set].append(mini_indices) \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AA034_D1S4': [[80, 131, 50, 73, 40],\n",
       "  [131, 70, 17, 26, 109],\n",
       "  [50, 96, 97, 40, 43],\n",
       "  [70, 40, 50, 26, 43],\n",
       "  [17, 50, 70, 111, 131],\n",
       "  [26, 96, 131, 50, 73],\n",
       "  [97, 26, 54, 80, 109],\n",
       "  [26, 43, 96, 50, 80],\n",
       "  [97, 50, 26, 73, 40],\n",
       "  [109, 73, 70, 131, 80],\n",
       "  [111, 26, 73, 80, 43],\n",
       "  [131, 80, 97, 111, 17],\n",
       "  [111, 96, 40, 97, 43],\n",
       "  [109, 40, 43, 70, 96],\n",
       "  [40, 70, 54, 113, 97],\n",
       "  [43, 131, 54, 111, 70],\n",
       "  [97, 17, 70, 131, 43],\n",
       "  [17, 96, 70, 111, 113],\n",
       "  [111, 109, 50, 131, 96],\n",
       "  [96, 70, 113, 54, 131],\n",
       "  [26, 109, 50, 17, 40],\n",
       "  [96, 17, 109, 73, 131],\n",
       "  [40, 70, 109, 17, 80],\n",
       "  [70, 43, 113, 96, 17],\n",
       "  [50, 131, 70, 109, 26],\n",
       "  [17, 131, 40, 54, 43],\n",
       "  [40, 113, 80, 109, 111],\n",
       "  [97, 70, 96, 17, 26],\n",
       "  [97, 80, 113, 43, 111],\n",
       "  [96, 70, 17, 40, 26]]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cells_dict[\"cross_session_same_day\"][\"AA034_D1S1\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cross_animal': {'AA034_D1S1': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 1],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]], dtype=int8),\n",
       "  'AA036_D2S1': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 1],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 1, 1]], dtype=int8),\n",
       "  'AA058_D1S1': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 1],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 1, 1]], dtype=int8),\n",
       "  'PL010_D1S1': array([[0, 0, 0, ..., 0, 1, 1],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 1],\n",
       "         [0, 0, 0, ..., 0, 0, 1]], dtype=int8)},\n",
       " 'cross_day_cross_session': {'AA034_D1S1': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]], dtype=int8),\n",
       "  'AA036_D2S1': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 1],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 1, 0, 0]], dtype=int8),\n",
       "  'AA058_D1S1': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 1, 1],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 1, 1]], dtype=int8),\n",
       "  'PL010_D1S1': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 1],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]], dtype=int8)},\n",
       " 'cross_day_same_session': {'AA034_D1S1': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 1, 1],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]], dtype=int8),\n",
       "  'AA036_D2S1': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 1],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 1]], dtype=int8),\n",
       "  'AA058_D1S1': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]], dtype=int8),\n",
       "  'PL010_D1S1': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 1, 1]], dtype=int8)},\n",
       " 'cross_session_same_day': {'AA034_D1S1': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 1, 1],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 1, 1]], dtype=int8),\n",
       "  'AA036_D2S1': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 1, 1, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]], dtype=int8),\n",
       "  'AA058_D1S1': array([[0, 0, 0, ..., 0, 0, 1],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 1],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]], dtype=int8),\n",
       "  'PL010_D1S1': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 1, 1],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 1]], dtype=int8)},\n",
       " 'within_session': {'AA034_D1S1': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 1, 1],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]], dtype=int8),\n",
       "  'AA036_D2S1': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 1],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 1]], dtype=int8),\n",
       "  'AA058_D1S1': array([[0, 0, 0, ..., 0, 0, 1],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 1],\n",
       "         [0, 0, 0, ..., 0, 1, 1],\n",
       "         [0, 0, 0, ..., 0, 0, 1]], dtype=int8),\n",
       "  'PL010_D1S1': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 1]], dtype=int8)}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cell_exploration_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
